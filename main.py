import os
import json
import argparse
from dotenv import load_dotenv
from openai import OpenAI
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from pathlib import Path
import markdown

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Embeddingãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆç¯€ç´„ç‰ˆï¼‰
embedding = OpenAIEmbeddings(
    model="text-embedding-3-small",
    dimensions=1536
)

# ãƒŠãƒ¬ãƒƒã‚¸èª­ã¿è¾¼ã¿é–¢æ•°ï¼ˆJSON & Markdownå¯¾å¿œï¼‰
def load_knowledge(folder_path: str, tag_filter: list[str] = None):
    documents = []
    for filepath in Path(folder_path).glob("**/*"):
        if filepath.suffix == ".json":
            with open(filepath, "r", encoding="utf-8") as f:
                data = json.load(f)
                for item in data:
                    tags = item.get("tags", [])
                    if tag_filter and not any(tag in tags for tag in tag_filter):
                        continue
                    doc = Document(
                        page_content=item["content"],
                        metadata={"title": item.get("title"), "tags": ", ".join(tags)}
                    )
                    documents.append(doc)
        elif filepath.suffix == ".md":
            with open(filepath, "r", encoding="utf-8") as f:
                content = f.read()
                doc = Document(
                    page_content=content,
                    metadata={"title": filepath.stem, "tags": "markdown"}
                )
                documents.append(doc)
    return documents

# ãƒ™ã‚¯ãƒˆãƒ«DBä½œæˆï¼ˆæ°¸ç¶šåŒ–ã›ãšéƒ½åº¦ä½œæˆï¼‰
def create_vectorstore(docs):
    return Chroma.from_documents(docs, embedding=embedding, collection_name="filtered-knowhow")

# é¡ä¼¼ãƒŠãƒ¬ãƒƒã‚¸ã‚’æ¤œç´¢ï¼ˆã‚¹ã‚³ã‚¢ä»˜ãï¼‰
def search_knowledge(db, query, k=3):
    return db.similarity_search_with_score(query, k=k)

# å›ç­”ç”Ÿæˆ
def ask_gpt(knowledge, query):
    context = "\n\n".join([doc.page_content for doc, _ in knowledge])
    prompt = f"""
    ã‚ãªãŸã¯æ¢ç´¢å‹ãƒ†ã‚¹ãƒˆã®å°‚é–€å®¶ã§ã™ã€‚
    ä»¥ä¸‹ã®ãƒŠãƒ¬ãƒƒã‚¸ã¨è³ªå•ã‚’å‚è€ƒã«ã€å…·ä½“çš„ãªãƒ†ã‚¹ãƒˆè¦³ç‚¹ã‚’5ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚

    ãƒŠãƒ¬ãƒƒã‚¸:
    {context}

    è³ªå•:
    {query}
    """
    res = client.chat.completions.create(
        model="gpt-5-nano",
        messages=[{"role": "user", "content": prompt}]
    )
    return res.choices[0].message.content

# ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
def save_report_md_html(query, results, answer, outdir="output"):
    os.makedirs(outdir, exist_ok=True)
    base = Path(outdir) / query.replace(" ", "_")

    # Markdownä¿å­˜
    md_path = base.with_suffix(".md")
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(f"# è³ªå•: {query}\n\n")
        f.write("## ğŸ” é¡ä¼¼ãƒŠãƒ¬ãƒƒã‚¸\n")
        for i, (doc, score) in enumerate(results):
            f.write(f"### {i+1}. {doc.metadata.get('title')} (score: {score:.4f})\n")
            f.write(f"- ã‚¿ã‚°: {doc.metadata.get('tags')}\n")
            f.write(f"\n{doc.page_content}\n\n")
        f.write("## ğŸ§  ChatGPTã®å›ç­”\n\n")
        f.write(answer)

    # HTMLä¿å­˜
    html_path = base.with_suffix(".html")
    with open(html_path, "w", encoding="utf-8") as f:
        html = markdown.markdown(Path(md_path).read_text(), extensions=["extra", "tables"])
        f.write(f"<html><body>{html}</body></html>")

# CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
def main():
    parser = argparse.ArgumentParser(description="RAG CLI with JSON/Markdown knowledge and tag filtering")
    parser.add_argument("--query", type=str, required=True, help="è³ªå•å†…å®¹")
    parser.add_argument("--tags", nargs="*", help="ã‚¿ã‚°ã§ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹ï¼ˆã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰")
    args = parser.parse_args()

    print("ğŸ” ãƒŠãƒ¬ãƒƒã‚¸ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    knowledge = load_knowledge("knowledge", tag_filter=args.tags)
    print(f"âœ… {len(knowledge)} ä»¶ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    db = create_vectorstore(knowledge)

    print("ğŸ” é¡ä¼¼ãƒŠãƒ¬ãƒƒã‚¸ã‚’æ¤œç´¢ä¸­...")
    results = search_knowledge(db, args.query)

    print("\nğŸ“š é¡ä¼¼ãƒŠãƒ¬ãƒƒã‚¸:")
    for i, (doc, score) in enumerate(results):
        print(f"--- {i+1} ---\nã‚¿ã‚¤ãƒˆãƒ«: {doc.metadata.get('title')}\nã‚¿ã‚°: {doc.metadata.get('tags')}\nã‚¹ã‚³ã‚¢: {score:.4f}\nå†…å®¹: {doc.page_content}\n")

    print("ğŸ§  ChatGPTã«ã‚ˆã‚‹å›ç­”:")
    answer = ask_gpt(results, args.query)
    print("\n" + answer)

    save_report_md_html(args.query, results, answer)
    print("\nğŸ“ çµæœã‚’Markdownã¨HTMLã§ä¿å­˜ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
